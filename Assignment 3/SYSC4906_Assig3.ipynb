{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SYSC4906_Assig3_Template.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuXZ7kBp8kp5",
        "colab_type": "text"
      },
      "source": [
        "# SYSC4906 Assignment 3\n",
        "\n",
        "**Group Name:** Thao and Riley\n",
        "\n",
        "**Student names:** Thao-Tran Le-Phuong and Riley MacKinnon\n",
        "\n",
        "**Student numbers:** 100997443 and 100996542\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11rAz_wk_BoW",
        "colab_type": "text"
      },
      "source": [
        "# Discussion of Solution\n",
        "Your notebook must begin with **this** text cell containing a description of your solution. In this discussion, include links to any resources that you used in developing your solution. Use proper MarkDown syntax to format your discussion.**This description should be approximately 500 words in length and cover the following:**\n",
        "\n",
        "1. Which machine learning approach did you use?\n",
        "\n",
        "2. How did you split your data between training and testing? \n",
        "_(e.g. hold-out test, cross-validation, repeated bootstrap samples, etc)_\n",
        "\n",
        "3. How did you train your classifier?\n",
        "If you used transfer learning, describe how you did so.\n",
        "\n",
        "4. How did you estimate your future performance _(worst recall, best precision, overall accuracy)_?\n",
        "\n",
        "   **Here are our final predictions:**\n",
        "   1. Building with worst recall:\n",
        "   2. Building with best precision\n",
        "   3. Overall accuracy)\n",
        "\n",
        "5. Discuss the performance of your model. Which buildings did it do the best/worst on and why? What are the strengths and limitations of your method. \n",
        "\n",
        "6. What would you have done differently if you had more time?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7n6M_ws2dwHR",
        "colab_type": "text"
      },
      "source": [
        "# Code to Train Your Method\n",
        "_We will look at this, but will not run it when measuring your accuracy. Please structure your training code into logical steps, so that we can easily understand it_\n",
        "## Step 1: Load the image dataset..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QczBezAN8cgT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "13d11d45-677d-4c57-b087-bb1562559e0f"
      },
      "source": [
        "from glob import glob\n",
        "from shutil import copy2\n",
        "\n",
        "!git clone https://github.com/Thao-Tran/sysc4906\n",
        "\n",
        "IMG_DIR = 'sysc4906/Assignment 3/Images/'\n",
        "TRAIN_DIR = 'train'\n",
        "VAL_DIR = 'validation'\n",
        "TEST_DIR = 'test'\n",
        "FOLDS = 5\n",
        "buildings = ('AA','CB','CT','DT','FH','HP','HS','LB','MC','ME','ML','PA','RB','RO','SA','TB')\n",
        "\n",
        "for building in buildings:\n",
        "  building_glob = glob(IMG_DIR+building+'/*.jpg')\n",
        "  training_size = int(0.85*len(building_glob))\n",
        "  fold_size = training_size // FOLDS\n",
        "  training_set = building_glob.copy()[:training_size]\n",
        "\n",
        "  for fold in range(FOLDS):\n",
        "    if fold < FOLDS - 1:\n",
        "      validation_set = training_set.copy()[fold_size*fold:fold_size*(fold+1)]\n",
        "      del training_set[fold_size*fold:fold_size*(fold+1)]\n",
        "    else:\n",
        "      validation_set = training_set.copy()[fold_size*fold:]\n",
        "      del training_set[fold_size*fold:]\n",
        "    \n",
        "    %mkdir -p /content/{fold}/{TRAIN_DIR}/{building}\n",
        "    %mkdir -p /content/{fold}/{VAL_DIR}/{building}\n",
        "    for path in training_set:\n",
        "      #%cp {path.replace(' ', '\\ ')} /content/{fold}/{TRAIN_DIR}/{building}\n",
        "      copy2(path, str(fold)+'/'+TRAIN_DIR+'/'+building)\n",
        "    for path in validation_set:\n",
        "      #%cp {path.replace(' ', '\\ ')} /content/{fold}/{VAL_DIR}/{building}\n",
        "      copy2(path, str(fold)+'/'+VAL_DIR+'/'+building)\n",
        "\n",
        "  %mkdir -p {TEST_DIR}/{building}\n",
        "\n",
        "  for path in building_glob[training_size:]:\n",
        "    #%cp {path.replace(' ', '\\ ')} {TEST_DIR}/{building}/\n",
        "    copy2(path, TEST_DIR+'/'+building)\n",
        "\n",
        "#rm -rf sysc4906"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'sysc4906'...\n",
            "remote: Enumerating objects: 3711, done.\u001b[K\n",
            "remote: Total 3711 (delta 0), reused 0 (delta 0), pack-reused 3711\u001b[K\n",
            "Receiving objects: 100% (3711/3711), 218.57 MiB | 40.92 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n",
            "Checking out files: 100% (3647/3647), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhiAFspaI6iY",
        "colab_type": "text"
      },
      "source": [
        "##Step N: Save the model to file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yozoCbdpI_fz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0be3ae33-ecf0-4526-b4fe-93437e3873f5"
      },
      "source": [
        "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "\n",
        "CLASSES = 16\n",
        "WIDTH = 500\n",
        "HEIGHT = 500\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "STEPS_PER_EPOCH = 3\n",
        "VALIDATION_STEPS = 1\n",
        "\n",
        "for fold in range(FOLDS):\n",
        "  base_model = InceptionV3(weights='imagenet', include_top=False)\n",
        "\n",
        "  x = base_model.output\n",
        "  x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
        "  x = Dropout(0.5)(x)\n",
        "  predictions = Dense(CLASSES, activation='softmax')(x)\n",
        "  model = Model(inputs=base_model.input, outputs=predictions)\n",
        "  for layer in base_model.layers:\n",
        "      layer.trainable = False\n",
        "\n",
        "  model.compile(optimizer='adam',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  train_datagen = ImageDataGenerator(\n",
        "      preprocessing_function=preprocess_input,\n",
        "      width_shift_range=0.3,\n",
        "      height_shift_range=0.3,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "  validation_datagen = ImageDataGenerator(\n",
        "      preprocessing_function=preprocess_input,\n",
        "      width_shift_range=0.3,\n",
        "      height_shift_range=0.3,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "  train_generator = train_datagen.flow_from_directory(\n",
        "      str(fold)+'/'+TRAIN_DIR,\n",
        "      target_size=(WIDTH,HEIGHT),\n",
        "      batch_size=BATCH_SIZE,\n",
        "      class_mode='categorical')\n",
        "\n",
        "  validation_generator = validation_datagen.flow_from_directory(\n",
        "      str(fold)+'/'+VAL_DIR,\n",
        "      target_size=(WIDTH,HEIGHT),\n",
        "      batch_size=BATCH_SIZE,\n",
        "      class_mode='categorical')\n",
        "\n",
        "  history = model.fit_generator(\n",
        "      train_generator,\n",
        "      epochs=EPOCHS,\n",
        "      steps_per_epoch=STEPS_PER_EPOCH,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=VALIDATION_STEPS)\n",
        "    \n",
        "  model.save(str(fold)+'.model')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Found 2280 images belonging to 16 classes.\n",
            "Found 565 images belonging to 16 classes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/10\n",
            "3/3 [==============================] - 28s 9s/step - loss: 3.1101 - acc: 0.0521 - val_loss: 2.7726 - val_acc: 0.0625\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 4s 1s/step - loss: 2.9734 - acc: 0.0104 - val_loss: 2.9140 - val_acc: 0.0312\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 9s 3s/step - loss: 3.0742 - acc: 0.0521 - val_loss: 2.9595 - val_acc: 0.0625\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 11s 4s/step - loss: 3.0475 - acc: 0.0417 - val_loss: 2.7640 - val_acc: 0.0312\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 10s 3s/step - loss: 2.9524 - acc: 0.1146 - val_loss: 2.7890 - val_acc: 0.0625\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 9s 3s/step - loss: 2.9088 - acc: 0.0729 - val_loss: 2.7171 - val_acc: 0.0312\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 8s 3s/step - loss: 2.8271 - acc: 0.0799 - val_loss: 2.7330 - val_acc: 0.0625\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 8s 3s/step - loss: 2.9194 - acc: 0.0938 - val_loss: 2.8903 - val_acc: 0.0625\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 7s 2s/step - loss: 2.7965 - acc: 0.1250 - val_loss: 2.8151 - val_acc: 0.0312\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 7s 2s/step - loss: 2.8277 - acc: 0.1042 - val_loss: 2.7573 - val_acc: 0.0625\n",
            "Found 1715 images belonging to 16 classes.\n",
            "Found 565 images belonging to 16 classes.\n",
            "Epoch 1/10\n",
            "3/3 [==============================] - 22s 7s/step - loss: 3.1059 - acc: 0.1042 - val_loss: 2.8165 - val_acc: 0.0938\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 6s 2s/step - loss: 3.1689 - acc: 0.0625 - val_loss: 2.7953 - val_acc: 0.0625\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 10s 3s/step - loss: 2.8895 - acc: 0.0208 - val_loss: 2.9117 - val_acc: 0.0938\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 11s 4s/step - loss: 2.9308 - acc: 0.0625 - val_loss: 3.0441 - val_acc: 0.0000e+00\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 10s 3s/step - loss: 2.9210 - acc: 0.0521 - val_loss: 2.9292 - val_acc: 0.0938\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 8s 3s/step - loss: 2.9011 - acc: 0.0833 - val_loss: 2.6578 - val_acc: 0.1875\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 8s 3s/step - loss: 2.9183 - acc: 0.0833 - val_loss: 2.8085 - val_acc: 0.0312\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 8s 3s/step - loss: 2.8631 - acc: 0.0833 - val_loss: 2.8312 - val_acc: 0.0625\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 9s 3s/step - loss: 2.7252 - acc: 0.1837 - val_loss: 2.6860 - val_acc: 0.1562\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 6s 2s/step - loss: 2.7745 - acc: 0.1354 - val_loss: 2.8378 - val_acc: 0.0312\n",
            "Found 1150 images belonging to 16 classes.\n",
            "Found 565 images belonging to 16 classes.\n",
            "Epoch 1/10\n",
            "3/3 [==============================] - 34s 11s/step - loss: 2.9837 - acc: 0.0521 - val_loss: 2.8860 - val_acc: 0.0625\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 4s 1s/step - loss: 2.9371 - acc: 0.0417 - val_loss: 2.9229 - val_acc: 0.0312\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 8s 3s/step - loss: 3.0801 - acc: 0.1146 - val_loss: 2.7988 - val_acc: 0.0938\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 11s 4s/step - loss: 2.9468 - acc: 0.0521 - val_loss: 2.8594 - val_acc: 0.1875\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 11s 4s/step - loss: 3.0190 - acc: 0.0938 - val_loss: 2.7084 - val_acc: 0.1562\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 9s 3s/step - loss: 2.9023 - acc: 0.0729 - val_loss: 2.7767 - val_acc: 0.0938\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 9s 3s/step - loss: 2.8819 - acc: 0.1042 - val_loss: 2.7962 - val_acc: 0.0312\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 12s 4s/step - loss: 2.8656 - acc: 0.0963 - val_loss: 2.7854 - val_acc: 0.0312\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 6s 2s/step - loss: 2.8453 - acc: 0.1042 - val_loss: 2.5518 - val_acc: 0.2500\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 8s 3s/step - loss: 2.8455 - acc: 0.0833 - val_loss: 2.7500 - val_acc: 0.1250\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-a71968f0a0f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m       validation_steps=VALIDATION_STEPS)\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m         \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_write_to_gcs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36msave_wrapper\u001b[0;34m(obj, filepath, overwrite, *args, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0msave_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msave_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m             \u001b[0m_serialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'write'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;31m# write as binary stream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36m_serialize_model\u001b[0;34m(model, h5dict, include_optimizer)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mlayer_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_weights_group\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0msymbolic_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mweight_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0mweight_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_get_value\u001b[0;34m(ops)\u001b[0m\n\u001b[1;32m   2680\u001b[0m     \"\"\"\n\u001b[1;32m   2681\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2682\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2683\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2684\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SuJ9U-W1vGh",
        "colab_type": "text"
      },
      "source": [
        "#Required functions to test your method\n",
        "_These are the five required methods that you must implement._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGTFt3HCBtoC",
        "colab_type": "text"
      },
      "source": [
        "## prepareModel()\n",
        "This function should prepare your model for multiple invocations of classifyImage(fname). For example, this function could be used to load a pre-trained model from a URL, where that model is then used by  classifyImage(fname). You should use global variables for any variables initialized by this function.\n",
        "\n",
        "Runtime of this method is **limited to 5 minutes**, so please don’t retrain your network here. All training should be captured in a pre-trained model to be loaded by this method.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHTnL0r_34Jn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import load_model\n",
        "\n",
        "HEIGHT = 500\n",
        "WIDTH = 500\n",
        "FOLDS = 5\n",
        "\n",
        "# List of building codes to use throughout notebook.\n",
        "buildingCodes = ('AA', 'CB', 'CT', 'DT', 'FH', 'HP', 'HS', 'LB', 'MC', 'ME', 'ML', 'PA', 'RB', 'RO', 'SA', 'TB')\n",
        "\n",
        "def prepareModel():\n",
        "  global models # Sample global variable that you may populate here.\n",
        "  models = []\n",
        "  for fold in range(folds):\n",
        "    models.append(load_model(str(fold)+'.model'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ruw5ut92JoTp",
        "colab_type": "text"
      },
      "source": [
        "## label = classifyImage(fname)\n",
        "Accepts a filename (e.g. ‘test/ME/testImage1.jpg’) of a square JPG image with size at least 500x500 pixels.\n",
        "Returns a 2-character label corresponding to the predicted building (see table of labels above)\n",
        "\n",
        "Any variables initialized by prepareModel() should be declared as global within this function if you want to access them (e.g. a pre-trained model)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKqBQblXJsfo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import image as kp_image\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "import numpy as np\n",
        "\n",
        "def classifyImage(fname):\n",
        "  global models # Sample global variable that you may populate in prepareModel and use here.\n",
        "\n",
        "  print(\"Predicting class of '{0:s}' using model '{1:s}'\".format(fname,model))\n",
        "  img = kp_image.load_img(fname, target_size=(HEIGHT, WIDTH))\n",
        "  x = kp_image.img_to_array(img)  # Convert image to nparray\n",
        "  x = np.expand_dims(x, axis=0)   # Need to pre-pend a dimension to indicate batch number.\n",
        "  x = preprocess_input(x)         # Normalize image to match how Inceptionv3 expects to receive images\n",
        "  preds = np.zeros(len(buildingCodes), dtype=int)\n",
        "  for model in models:\n",
        "    preds += model.predict(x)[0]        # Use the model to compute prediction score for each possible class\n",
        "  preds /= FOLDS\n",
        "  pred = ''\n",
        "  score = -1\n",
        "  for i in range(len(preds)):\n",
        "    if preds[i] > score:\n",
        "      pred = buildingCodes[i]\n",
        "      score = preds[i]\n",
        "  return pred\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flSl6rStZ-gy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from glob import glob\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "TEST_DIR = 'test'\n",
        "\n",
        "def get_metrics():\n",
        "  y_true = []\n",
        "  y_pred = []\n",
        "  for building in buildingCodes:\n",
        "    paths = glob(TEST_DIR+'/'+buildingCode+'/*.jpg')\n",
        "    y_true += building * len(paths)\n",
        "    y_pred += [classifyImage(path) for path in paths]\n",
        "  return confusion_matrix(y_true, y_pred), accuracy_score(y_true, y_pred)\n",
        "\n",
        "cm, accuracy = get_metrics()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhT_kBUtlbxV",
        "colab_type": "text"
      },
      "source": [
        "## label = worstRecall()\n",
        "Returns the label of a building that you expect will have to lowest recall, when tested on new images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WqzFBXXsD7_4",
        "colab": {}
      },
      "source": [
        "from glob import glob\n",
        "\n",
        "def worstRecall():\n",
        "  worst_recall = -1\n",
        "  building = ''\n",
        "  for i in range(len(buildingCodes)):\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    recall = tp / (tp+fn)\n",
        "    if worst_recall == -1 or recall < worst_recall:\n",
        "      worst_recall = recall\n",
        "      building = buildingCodes[i]\n",
        "  return building\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wPvzTsdhD_pT"
      },
      "source": [
        "## label = bestPrecision()\n",
        "Returns the label of a building that you expect will have to highest precision, when tested on new images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lYlqHWZ8D_pU",
        "colab": {}
      },
      "source": [
        "def bestPrecision():\n",
        "  best_precision = -1\n",
        "  building = ''\n",
        "  for i in range(len(buildingCodes)):\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    precision = tp / (tp+fp)\n",
        "    if precision > best_precision:\n",
        "      best_precision = precision\n",
        "      building = buildingCodes[i]\n",
        "  return building\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFuh44eXV5M_",
        "colab_type": "text"
      },
      "source": [
        "##acc_score = estimatedAccuracy()\n",
        "Returns the accuracy (between [0.0,1.0]) that you expect to achieve across all test images, assuming that each building is equally represented\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZDRNC9RWAQt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to return estimated accuracy that will be obtained across all test images\n",
        "def estimatedAccuracy():\n",
        "  return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cp01v7PEEwa7",
        "colab_type": "text"
      },
      "source": [
        "# Test required functions\n",
        "_We will replace the text below with our actual test code..._"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5_x2SOrFNlY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from PIL import Image, ExifTags\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "\n",
        "\n",
        "# First prepare the model:\n",
        "prepareModel() # Limited to 5 minutes...\n",
        "\n",
        "# Load (secret) test data into local Colab environment\n",
        "!wget https://github.com/jrgreen7/SYSC4906/blob/master/Assignments/Assignment3/Images/SampleImages.zip?raw=true\n",
        "!unzip SampleImages.zip?raw=true #Should create 4 images\n",
        "test_images = sorted(glob('SampleImages/*.jpg'))\n",
        "actual_labels = (buildingCodes[0],buildingCodes[1],buildingCodes[3],buildingCodes[6])\n",
        "\n",
        "# Classify sample test images:\n",
        "TP = 0\n",
        "for imgFname,actual_label in (zip(test_images,actual_labels)):\n",
        "  pred_label = classifyImage(imgFname) # Predict the label of this image file\n",
        "\n",
        "  # Plot the image with actual and predicted labels\n",
        "  # Note that we may have to rotate the image, depending on the \n",
        "  # orientation of the camera. Use EXIF tags for this:\n",
        "  im = Image.open(imgFname)\n",
        "  for orientation in ExifTags.TAGS.keys() : \n",
        "    if ExifTags.TAGS[orientation]=='Orientation' : break \n",
        "  exif=dict(im._getexif().items())\n",
        "\n",
        "  if exif[orientation] == 3 : \n",
        "    im=im.rotate(180, expand=True)\n",
        "  elif exif[orientation] == 6 : \n",
        "    im=im.rotate(270, expand=True)\n",
        "  elif exif[orientation] == 8 : \n",
        "    im=im.rotate(90, expand=True)\n",
        "\n",
        "  im = im.convert('RGB') # May not be necessary?\n",
        "\n",
        "  plt.title(\"Sample test image of {0:s} predicted as {1:s}\".format(actual_label, pred_label))\n",
        "  plt.imshow(np.asarray(im))\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "  if (pred_label==actual_label):\n",
        "    print('Correct!')\n",
        "    TP += 1\n",
        "  else:\n",
        "    print(\"Incorrect...\")\n",
        "\n",
        "# Print the predicted performance:\n",
        "print(\"Expected that worst recall would be on {0:s}\".format(worstRecall()))\n",
        "print(\"Expected that best precision would be on {0:s}\".format(bestPrecision()))\n",
        "print(\"Expected total accuracy would be {0:.3f}\".format(estimatedAccuracy()))\n",
        "print(\"Actual total accuracy is {0:.3f}\".format((TP)/(len(test_images))))\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}